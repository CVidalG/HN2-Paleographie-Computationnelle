{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Définition et entraînement d'un GAN de zéro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "latent_dim = 100\n",
    "image_size = 28 * 28\n",
    "batch_size = 128\n",
    "n_epochs = 50\n",
    "sample_interval = 500\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "train_ds = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "dl = DataLoader(dataset=train_ds, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_data_target(size):\n",
    "    return torch.ones(size, 1).to(device)\n",
    "\n",
    "def fake_data_target(size):\n",
    "    return torch.zeros(size, 1).to(device)\n",
    "\n",
    "def imgs_to_vec(imgs):\n",
    "    return imgs.view(imgs.size(0), -1)\n",
    "\n",
    "def vec_to_imgs(vec):\n",
    "    return vec.view(vec.size(0), 1, 28, 28)\n",
    "\n",
    "def noise(size, latent_dim=100):\n",
    "    return torch.randn(size, latent_dim).to(device)\n",
    "\n",
    "def display_images(imgs, n_cols=4, figsize=(8, 8)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(min(len(imgs), 16)):  \n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(imgs[i].cpu().data.numpy().reshape(28, 28), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "image_batch = next(iter(dl))[0]\n",
    "print(\"Viz:\")\n",
    "display_images(image_batch)\n",
    "\n",
    "\n",
    "class DiscriminatorNet(nn.Module):\n",
    "    def __init__(self, img_size=28):\n",
    "        super(DiscriminatorNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(img_size * img_size, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class GeneratorNet(nn.Module):\n",
    "    def __init__(self, latent_dim=100, img_size=28):\n",
    "        super(GeneratorNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, img_size * img_size),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "discriminator = DiscriminatorNet().to(device)\n",
    "generator = GeneratorNet().to(device)\n",
    "\n",
    "\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "\n",
    "def train_mnist_gan(d, g, d_optim, g_optim, loss_fn, dl, n_epochs, device):\n",
    "    fixed_noise = noise(16)\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs), desc=\"Training Progress\"):\n",
    "        d.train()\n",
    "        g.train()\n",
    "        d_running_loss = 0\n",
    "        g_running_loss = 0\n",
    "\n",
    "        for batch_idx, (real_images, _) in enumerate(dl):\n",
    "            real_images = real_images.to(device)\n",
    "            batch_size = real_images.size(0)\n",
    "\n",
    "            \n",
    "            d_optim.zero_grad()\n",
    "            real_images = imgs_to_vec(real_images)\n",
    "            real_targets = real_data_target(batch_size)\n",
    "            fake_targets = fake_data_target(batch_size)\n",
    "\n",
    "            real_loss = loss_fn(d(real_images), real_targets)\n",
    "            fake_images = g(noise(batch_size)).detach()\n",
    "            fake_loss = loss_fn(d(fake_images), fake_targets)\n",
    "\n",
    "            d_loss = real_loss + fake_loss\n",
    "            d_loss.backward()\n",
    "            d_optim.step()\n",
    "            d_running_loss += d_loss.item()\n",
    "\n",
    "            \n",
    "            g_optim.zero_grad()\n",
    "            fake_images = g(noise(batch_size))\n",
    "            g_loss = loss_fn(d(fake_images), real_targets)\n",
    "            g_loss.backward()\n",
    "            g_optim.step()\n",
    "            g_running_loss += g_loss.item()\n",
    "\n",
    "            if batch_idx % sample_interval == 0:\n",
    "                print(f\"Epoch [{epoch}/{n_epochs}] Batch {batch_idx}/{len(dl)} \\\n",
    "                      Loss D: {d_loss:.4f}, loss G: {g_loss:.4f}\")\n",
    "                g.eval()\n",
    "                with torch.no_grad():\n",
    "                    test_images = vec_to_imgs(g(fixed_noise)).cpu()\n",
    "                    display_images(test_images)\n",
    "                g.train()\n",
    "\n",
    "        d_epoch_loss = d_running_loss / len(dl)\n",
    "        g_epoch_loss = g_running_loss / len(dl)\n",
    "        d_losses.append(d_epoch_loss)\n",
    "        g_losses.append(g_epoch_loss)\n",
    "\n",
    "    return d_losses, g_losses\n",
    "\n",
    "\n",
    "d_losses, g_losses = train_mnist_gan(discriminator, generator, d_optimizer, g_optimizer, loss_fn, dl, n_epochs, device)\n",
    "\n",
    "\n",
    "plt.plot(d_losses, label='Discriminator')\n",
    "plt.plot(g_losses, label='Generator')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "torch.save(generator.state_dict(), \"gan_generator_pytorch.pth\")\n",
    "\n",
    "\n",
    "def generate_and_plot_image(generator, device, latent_dim=100):\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(1, latent_dim).to(device)\n",
    "        gen_img = generator(z).cpu().view(28, 28).numpy()\n",
    "        gen_img = 0.5 * gen_img + 0.5\n",
    "        plt.imshow(gen_img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "generate_and_plot_image(generator, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def analyze_strokes(image):\n",
    "    # Convert the image to grayscale (if not already)\n",
    "    if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Convert to 8-bit pixel values\n",
    "    image = np.uint8(image * 255)\n",
    "\n",
    "    # Apply a Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "    # Use Canny edge detection to find edges in the image\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "    # Find contours in the edged image\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Analyze the contours to determine stroke features\n",
    "    stroke_features = []\n",
    "    for contour in contours:\n",
    "        # Calculate the bounding box of the contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        aspect_ratio = w / float(h)\n",
    "        extent = cv2.contourArea(contour) / float(w * h)\n",
    "        stroke_features.append((aspect_ratio, extent))\n",
    "\n",
    "    return stroke_features\n",
    "\n",
    "# Function to display and analyze generated images\n",
    "def inspect_generated_images(generator, device, latent_dim=100, num_images=5):\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_images, latent_dim).to(device)\n",
    "        gen_imgs = generator(z).cpu().view(-1, 28, 28).numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, img in enumerate(gen_imgs):\n",
    "        plt.subplot(1, num_images, i + 1)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        # Analyze stroke features\n",
    "        features = analyze_strokes(img)\n",
    "        print(f\"Image {i+1} Stroke Features: {features}\")\n",
    "    plt.show()\n",
    "\n",
    "# Inspect generated images\n",
    "inspect_generated_images(generator, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
